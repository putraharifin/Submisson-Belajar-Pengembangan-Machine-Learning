# -*- coding: utf-8 -*-
"""Submission1_NLP_ Muhammad Putra Harifin Pane.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16u_YQ5j8Zj_jezkmAYBvNW4T0PDc-3nN

# Muhammad Putra Harifin Pane
"""

# Panggil Dataset kedalam program
from google.colab import files
uploaded = files.upload()

# import pandas
import pandas as pd

# load dataset
df = pd.read_csv('bbc-text.csv')
df.head(10)

# Melihat informasi dataset
df.info()

# data columns
df.columns

"""dataset memiliki 2 kolom yaitu kolom category dan kolom text"""

# total data
df.shape

"""memiliki total data lebih dari 2000 sampel"""

# categories
df.category.value_counts()

"""melakukan one hot econding"""

category = pd.get_dummies(df.category)
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns='category')
df_baru

text = df_baru['text'].values
label = df_baru[['business', 'entertainment', 'politics', 'sport', 'tech']].values

#memisahkan data training dan data testing
from sklearn.model_selection import train_test_split
text_latih, text_test, label_latih, label_test = train_test_split(text, label, test_size=0.2)

#menggunakan fungsi tokenizer
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(text_latih)
tokenizer.fit_on_texts(text_test)

sekuens_latih = tokenizer.texts_to_sequences(text_latih)
sekuens_test = tokenizer.texts_to_sequences(text_test)

padded_latih = pad_sequences(sekuens_latih)
padded_test = pad_sequences(sekuens_test)

#menggunakan embendding
import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(5, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

num_epochs = 10
history = model.fit(padded_latih, label_latih, epochs=num_epochs,
                    validation_data=(padded_test, label_test), verbose=2)

#plot of accuracy
import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

#plot of loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()